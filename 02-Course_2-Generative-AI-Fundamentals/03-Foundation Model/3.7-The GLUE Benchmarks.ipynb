{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GLUE Benchmarks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GLUE benchmarks serve as an essential tool to assess an AI's grasp of human language, covering diverse tasks, from grammar checking to complex sentence relationship analysis. By putting AI models through these varied linguistic challenges, we can gauge their readiness for real-world tasks and uncover any potential weaknesses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Terms Explained:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Semantic Equivalence```: When different phrases or sentences convey the same meaning or idea.\n",
    "\n",
    "```Textual Entailment```: The relationship between text fragments where one fragment follows logically from the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLUE Tasks / Benchmarks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Short Name | Full Name | Description |\n",
    "|-------|----------------------------------------|------------------------------------------|\n",
    "| CoLA  | Corpus of Linguistic Acceptability    | Measures the ability to determine if an English sentence is linguistically acceptable.             |\n",
    "| SST-2 | Stanford Sentiment Treebank           | Consists of sentences from movie reviews and human annotations about their sentiment.              |\n",
    "| MRPC  | Microsoft Research Paraphrase Corpus | Focuses on identifying whether two sentences are paraphrases of each other.                       |\n",
    "| STS-B | Semantic Textual Similarity Benchmark | Involves determining how similar two sentences are in terms of semantic content.                  |\n",
    "| QQP   | Quora Question Pairs                  | Aims to identify whether two questions asked on Quora are semantically equivalent.                 |\n",
    "| MNLI  | Multi-Genre Natural Language Inference | Consists of sentence pairs labeled for textual entailment across multiple genres of text.          |\n",
    "| QNLI  | Question Natural Language Inference   | Involves determining whether the content of a paragraph contains the answer to a question.         |\n",
    "| RTE   | Recognizing Textual Entailment        | Requires understanding whether one sentence entails another.                                       |\n",
    "| WNLI  | Winograd Natural Language Inference   | Tests a system's reading comprehension by having it determine the correct referent of a pronoun in a sentence, where understanding depends on contextual information provided by specific words or phrases. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
