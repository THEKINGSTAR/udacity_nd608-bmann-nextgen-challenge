{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Training Loops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A PyTorch training loop is an essential part of building a neural network model, which helps us teach the computer how to make predictions or decisions based on data. By using this loop, we gradually improve our model's accuracy through a process of learning from its mistakes and adjusting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ```Technical Terms Explained:```\n",
    "\n",
    "- **Training Loop**: The cycle that a neural network goes through many times to learn from the data by making predictions, checking errors, and improving itself.\n",
    "\n",
    "- **Batches**: Batches are small, evenly divided parts of data that the AI looks at and learns from each step of the way.\n",
    "\n",
    "- **Epochs**: A complete pass through the entire training dataset. The more epochs, the more the computer goes over the material to learn.\n",
    "\n",
    "- **Loss functions**: They measure how well a model is performing by calculating the difference between the model's predictions and the actual results.\n",
    "\n",
    "- **Optimizer**: Part of the neural network's brain that makes decisions on how to change the network to get better at its job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```Create a Number Sum Dataset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        number1 = float(self.numbers[index // len(self.numbers)])\n",
    "        number2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([number1, number2]), torch.tensor([number1 + number2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([1., 4.]), tensor([5.]))\n",
      "(tensor([1., 5.]), tensor([6.]))\n",
      "(tensor([1., 6.]), tensor([7.]))\n",
      "(tensor([1., 7.]), tensor([8.]))\n",
      "(tensor([1., 8.]), tensor([9.]))\n",
      "(tensor([1., 9.]), tensor([10.]))\n",
      "(tensor([ 1., 10.]), tensor([11.]))\n"
     ]
    }
   ],
   "source": [
    "dataset = NumberSumDataset(data_range=(1, 100))\n",
    "\n",
    "for i in range(10):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NumberSumDataset(data_range=(1, 100))\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Sum of Batch Losses =  16581.22852\n",
      "Epoch: 1, Sum of Batch Losses =  40291.76172\n",
      "Epoch: 2, Sum of Batch Losses =  22469.82227\n",
      "Epoch: 3, Sum of Batch Losses =  26830.44922\n",
      "Epoch: 4, Sum of Batch Losses =  31481.81250\n",
      "Epoch: 5, Sum of Batch Losses =  4874.49023\n",
      "Epoch: 6, Sum of Batch Losses =  28836.08984\n",
      "Epoch: 7, Sum of Batch Losses =  26683.90234\n",
      "Epoch: 8, Sum of Batch Losses =  38366.49609\n",
      "Epoch: 9, Sum of Batch Losses =  76963.42188\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 10 epochs\n",
    "for epoch in range(10):\n",
    "    loss = 0.0 \n",
    "    for numbser_pairs, sum in dataloader: # Itrate over the batches\n",
    "        prediction = model(numbser_pairs) # Compute the model output\n",
    "        loss = loss_function(prediction, sum) # Compute the loss\n",
    "        loss.backward # Preform backprogation\n",
    "        optimizer.step() # Update the model parameters\n",
    "        optimizer.zero_grad() # Zero the gradients\n",
    "\n",
    "        loss += loss.item() # Add the loss fo all batchse\n",
    "\n",
    "    # Print the loss fot thes epoch\n",
    "    print(\"Epoch: {}, Sum of Batch Losses =  {:.5f}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3243], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model 3 + 7\n",
    "model(torch.tensor([3.0, 7.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: The code in video has an issue where the lossvariable was used to calculate the total loss as well. In this case, for every batch the loss was considered twice. Here, we should have a separate variable total_lossto overcome the issue. The code snippets below have it corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Number Sum Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has two features—a pair of numbers—and a target value—the sum of those two numbers.\n",
    "\n",
    "Note that this is not actually a good use of deep learning. At the end of our training loop, the model still doesn't know how to add 3 + 7! The idea here is to use a simple example so it's easy to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = float(self.numbers[index // len(self.numbers)])\n",
    "        number2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([number1, number2]), torch.tensor([number1 + number2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([1., 4.]), tensor([5.]))\n",
      "(tensor([1., 5.]), tensor([6.]))\n"
     ]
    }
   ],
   "source": [
    "dataset = NumberSumDataset(data_range=(1, 100))\n",
    "\n",
    "for i in range(5):\n",
    "    print(dataset[i])\n",
    "# (tensor([1., 1.]), tensor([2.]))\n",
    "# (tensor([1., 2.]), tensor([3.]))\n",
    "# (tensor([1., 3.]), tensor([4.]))\n",
    "# (tensor([1., 4.]), tensor([5.]))\n",
    "# (tensor([1., 5.]), tensor([6.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Simple Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Components Needed for Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NumberSumDataset(data_range=(0, 100))\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "model = MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Sum of Batch Losses = 1.39096\n",
      "Epoch 1: Sum of Batch Losses = 1.37265\n",
      "Epoch 2: Sum of Batch Losses = 1.36436\n",
      "Epoch 3: Sum of Batch Losses = 1.32980\n",
      "Epoch 4: Sum of Batch Losses = 1.30485\n",
      "Epoch 5: Sum of Batch Losses = 1.28342\n",
      "Epoch 6: Sum of Batch Losses = 1.27212\n",
      "Epoch 7: Sum of Batch Losses = 1.25327\n",
      "Epoch 8: Sum of Batch Losses = 1.22868\n",
      "Epoch 9: Sum of Batch Losses = 1.20453\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0.0\n",
    "    for number_pairs, sums in dataloader:  # Iterate over the batches\n",
    "        predictions = model(number_pairs)  # Compute the model output\n",
    "        loss = loss_function(predictions, sums)  # Compute the loss\n",
    "        loss.backward()  # Perform backpropagation\n",
    "        optimizer.step()  # Update the parameters\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        total_loss += loss.item()  # Add the loss for all batches\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(\"Epoch {}: Sum of Batch Losses = {:.5f}\".format(epoch, total_loss))\n",
    "    # Epoch 0: Sum of Batch Losses = 118.82360\n",
    "    # Epoch 1: Sum of Batch Losses = 39.75702\n",
    "    # Epoch 2: Sum of Batch Losses = 2.16352\n",
    "    # Epoch 3: Sum of Batch Losses = 0.25178\n",
    "    # Epoch 4: Sum of Batch Losses = 0.22843\n",
    "    # Epoch 5: Sum of Batch Losses = 0.19182\n",
    "    # Epoch 6: Sum of Batch Losses = 0.15507\n",
    "    # Epoch 7: Sum of Batch Losses = 0.07789\n",
    "    # Epoch 8: Sum of Batch Losses = 0.06329\n",
    "    # Epoch 9: Sum of Batch Losses = 0.04936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the Model Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9194], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model on 3 + 7\n",
    "model(torch.tensor([3.0, 7.0]))\n",
    "# tensor([10.1067], grad_fn=<AddBackward0>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- [PyTorch quickstart tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
