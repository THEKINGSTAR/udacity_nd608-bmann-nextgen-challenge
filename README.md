# Udacity_nd608-bmann-nextgen-challenge

## **Overview**
This repository contains materials for the **Udacity Next Gen Tech Booster 24-25** and **Generative AI Fundamentals** courses. The content includes lecture notes, exercises, Jupyter notebooks, and additional resources to help students grasp foundational and advanced concepts in Generative AI.

---
## **Repository Structure**

### **1. Next Gen Tech Booster 24-25**
Located in `01-Course_1-Next-Gen-Tech-Booster-24-25`, this section contains:
- [Next Gen Tech Booster 24-25 Phase 1 Kick-off (PDF)](01-Course_1-Next-Gen-Tech-Booster-24-25/%5BExternal%5D%20Next%20Gen%20Tech%20Booster%2024-25%20%20Phase%201%20Kick-off.pdf)
- [Next Gen Tech Booster 24-25 Phase 1 Kick-off (PPTX)](01-Course_1-Next-Gen-Tech-Booster-24-25/%5BExternal%5D%20Next%20Gen%20Tech%20Booster%2024-25%20%20Phase%201%20Kick-off.pptx)

### **2. Generative AI Fundamentals**
Located in `02-Course_2-Generative-AI-Fundamentals`, this section is divided into five modules:

#### **01 - Introduction to Generative AI Fundamentals**
ðŸ“‚ `02-Course_2-Generative-AI-Fundamentals/01-intro_to_Generative_Ai_Fundamentals`
### **This modules contains**:

- Generating One Token at a Time
    - [Exercise2-generating-one-token-at-a-time.ipynb](02-Course_2-Generative-AI-Fundamentals/01-intro_to_Generative_Ai_Fundamentals/Exercise2-generating-one-token-at-a-time.ipynb)

- Solution: Generating One Token at a Time
    - [Exercise2-generating-one-token-at-a-time-solution.ipynb](02-Course_2-Generative-AI-Fundamentals/01-intro_to_Generative_Ai_Fundamentals/Exercise2-generating-one-token-at-a-time-solution.ipynb)

- [class_suggus.MD](./02-Course_2-Generative-AI-Fundamentals/01-intro_to_Generative_Ai_Fundamentals/class_suggus.MD)
- [students_classes_tables.MD](/02-Course_2-Generative-AI-Fundamentals/01-intro_to_Generative_Ai_Fundamentals/students_classes_tables.MD)





#### **02 - Deep Learning Fundamentals**
ðŸ“‚ `02-Course_2-Generative-AI-Fundamentals/02-deep_larning_fundamentals`
- Covers topics like PyTorch optimizers, datasets, training loops, Hugging Face models, and transfer learning.
- Contains hands-on exercises for implementing deep learning models.

### **This modules contains**:
- [PyTorch Optimizers](02-Course_2-Generative-AI-Fundamentals/02-deep_larning_fundamentals/2.10-PyTorch_Optimizers.ipynb)
- [PyTorch Datasets and Data Loaders](02-Course_2-Generative-AI-Fundamentals/02-deep_larning_fundamentals/2.11-PyTorch_Datasets_and_Data_Loaders.ipynb)
- [What Is Hugging Face?](02-Course_2-Generative-AI-Fundamentals/02-deep_larning_fundamentals/2.13-What%20Is%20Hugging%20Face.ipynb)
- [Pre-Trained Models and Transfer Learning](02-Course_2-Generative-AI-Fundamentals/02-deep_larning_fundamentals/2.20-Pre-Trained%20Models%20and%20Transfer%20Learning.ipynb)

#### **03 - Foundation Models**
ðŸ“‚ `02-Course_2-Generative-AI-Fundamentals/03-Foundation Model`
- Topics include foundation models vs. traditional models, architecture, data scale, biases, risks, and benchmarks.
- Hands-on exercises on using foundation models.

### **This modules contains**:
- [What Is a Foundation Model?](02-Course_2-Generative-AI-Fundamentals/03-Foundation%20Model/3.1-What%20Is%20a%20Foundation%20Model.ipynb)
- [Architecture and Scale](02-Course_2-Generative-AI-Fundamentals/03-Foundation%20Model/3.3-Architecture%20and%20Scale.ipynb)
- [The GLUE Benchmarks](02-Course_2-Generative-AI-Fundamentals/03-Foundation%20Model/3.7-The%20GLUE%20Benchmarks.ipynb)
- [Data Used for Training LLMs](02-Course_2-Generative-AI-Fundamentals/03-Foundation%20Model/3.9-Data%20Used%20for%20Training%20LLMs.ipynb)

#### **04 - Adapting Foundation Models**
ðŸ“‚ `02-Course_2-Generative-AI-Fundamentals/04-AdaptatiNG-Fundation-Model`
- Discusses adaptation techniques like retrieval-augmented generation, prompt engineering, and fine-tuning.
- Includes exercises on full fine-tuning BERT models and sentiment analysis.

### **This modules contains**:
- [What Is Adaptation?](02-Course_2-Generative-AI-Fundamentals/04-AdaptatiNG-Fundation-Model/4.1-What-Is-Adaptation.ipynb)
- [Prompt Design Techniques](02-Course_2-Generative-AI-Fundamentals/04-AdaptatiNG-Fundation-Model/4.4-Prompt%20Design%20Techniques.ipynb)
- [Zero-Shot Prompting](02-Course_2-Generative-AI-Fundamentals/04-AdaptatiNG-Fundation-Model/4.7-Zero-Shot%20Prompting.ipynb)
- [Fine-Tuning](02-Course_2-Generative-AI-Fundamentals/04-AdaptatiNG-Fundation-Model/4.15-Fine-Tuning.ipynb)

#### **05 - Certificate of Nanodegree Program Completion**
ðŸ“‚ `02-Course_2-Generative-AI-Fundamentals/05-Certificate-Of-Nanodegree-Program-Completion`
- Completion certificate from Udacity.

- [Certificate PDF](02-Course_2-Generative-AI-Fundamentals/05-Certificate-Of-Nanodegree-Program-Completion/Learn%20the%20Latest%20Tech%20Skills%3B%20Advance%20Your%20Career%20_%20Udacity.pdf)
---
## **How to Use This Repository**
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/Udacity_nd608-bmann-nextgen-challenge.git
   ```
2. Navigate to the desired course/module.
3. Open the Jupyter notebooks to explore concepts interactively.
4. Follow the exercises and review the provided solutions.

---
## **Requirements & Dependencies**
Ensure you have the following dependencies installed:
- Python 3.x
- Jupyter Notebook
- PyTorch
- Hugging Face Transformers
- Additional libraries as required in specific notebooks

Install dependencies using:
```bash
pip install -r requirements.txt
```
*(Note: A `requirements.txt` file should be included if necessary.)*

### **Resources:**
- [requirements.txt](./requirements.txt)

---
## **Contributing**
If you'd like to contribute:
1. Fork the repository.
2. Create a feature branch.
3. Submit a pull request with clear documentation of changes.

---
## **License**
This project is licensed under the MIT License.

---
## **Acknowledgments**
Special thanks to Udacity for providing this educational content and the Next Gen Tech Booster initiative for fostering AI learning.

Happy Learning! ðŸš€

